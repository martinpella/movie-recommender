{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import os, math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from torch import optim\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm_notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal is to create an effective Collaborative Filtering Model from scratch. We will use PyTorch as automatic differentiation and gpu programming tool."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use MovieLens dataset http://files.grouplens.org/datasets/movielens/ml-latest-small.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It contains 100,000 ratings applied to 9,000 movies by 700 users."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "PATH = os.getcwd() + '/data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(PATH + '/ratings.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>31</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1260759144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1029</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1260759179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1061</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1260759182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1129</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1260759185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1172</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1260759205</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId  movieId  rating   timestamp\n",
       "0       1       31     2.5  1260759144\n",
       "1       1     1029     3.0  1260759179\n",
       "2       1     1061     3.0  1260759182\n",
       "3       1     1129     2.0  1260759185\n",
       "4       1     1172     4.0  1260759205"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "userId and movieId are categorial variables that we will use as predictors and rating is the dependant variable, the outcome that we want to predict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100004, 4)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100004 entries, 0 to 100003\n",
      "Data columns (total 4 columns):\n",
      "userId       100004 non-null int64\n",
      "movieId      100004 non-null int64\n",
      "rating       100004 non-null float64\n",
      "timestamp    100004 non-null int64\n",
      "dtypes: float64(1), int64(3)\n",
      "memory usage: 3.1 MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are not missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>100004.000000</td>\n",
       "      <td>100004.000000</td>\n",
       "      <td>100004.000000</td>\n",
       "      <td>1.000040e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>347.011310</td>\n",
       "      <td>12548.664363</td>\n",
       "      <td>3.543608</td>\n",
       "      <td>1.129639e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>195.163838</td>\n",
       "      <td>26369.198969</td>\n",
       "      <td>1.058064</td>\n",
       "      <td>1.916858e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>7.896520e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>182.000000</td>\n",
       "      <td>1028.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>9.658478e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>367.000000</td>\n",
       "      <td>2406.500000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.110422e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>520.000000</td>\n",
       "      <td>5418.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.296192e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>671.000000</td>\n",
       "      <td>163949.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.476641e+09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              userId        movieId         rating     timestamp\n",
       "count  100004.000000  100004.000000  100004.000000  1.000040e+05\n",
       "mean      347.011310   12548.664363       3.543608  1.129639e+09\n",
       "std       195.163838   26369.198969       1.058064  1.916858e+08\n",
       "min         1.000000       1.000000       0.500000  7.896520e+08\n",
       "25%       182.000000    1028.000000       3.000000  9.658478e+08\n",
       "50%       367.000000    2406.500000       4.000000  1.110422e+09\n",
       "75%       520.000000    5418.000000       4.000000  1.296192e+09\n",
       "max       671.000000  163949.000000       5.000000  1.476641e+09"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rating values range is (0.5 - 5)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "movies ids are not contiguous, they start at 1 and go to 163949. This is not efficient when creating an embedding matrix. So, we get a list of unique movieId and then we create a mapping from every movieId to a contiguous integer. We also apply the same steps to userId just to be cautious."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "users = df['userId'].unique()\n",
    "movies = df['movieId'].unique()\n",
    "\n",
    "user2idx = {k: i for i, k in enumerate(users)}\n",
    "movie2idx = {k: i for i, k in enumerate(movies)}\n",
    "\n",
    "df['userId'] = df['userId'].apply(lambda x: user2idx[x])\n",
    "df['movieId'] = df['movieId'].apply(lambda x: movie2idx[x])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of users and movies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_users = len(df['userId'].unique())\n",
    "n_movies = len(df['movieId'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(671, 9066)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_users, n_movies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will not use timestamp column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.drop('timestamp', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train, valid split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We split the data into a standard 80 % training and 20 % validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n = df.shape[0]\n",
    "np.random.seed = 42\n",
    "n_val = int(n * 0.2)\n",
    "idxs = np.random.permutation(n)\n",
    "# validation indexes\n",
    "val_idxs = idxs[:n_val]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mask = np.zeros(len(df), dtype=bool)\n",
    "mask[np.array(val_idxs)] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create training and validation PyTorch dataloaders. They are a useful structure to get mini batches of data when fitting the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "train_dl = DataLoader(df[~mask].values, batch_size, shuffle=True, num_workers=1)\n",
    "valid_dl = DataLoader(df[mask].values, batch_size * 2, shuffle=False, num_workers=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to represent userId and movieId in a high dimentional space where each of them will be represented by a vector of n dimensions (number of factors). Then we will predict the rating of a particular user on a particular movie by calculating the dot product between their vectors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we are deciding if user X would like movie Z, we are saying:\n",
    "<br/>Which are the users that enjoyed movies like Z ? \n",
    "<br/>And which are the movies that were liked by people like user X?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embeddings dot product"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given a userId and a movieId, we want to look up into our users and embedding matrices to find their vectors of n factors and then take the dot product."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to create a PyTorch Module, something that we can use as a layer and as neural net.\n",
    "<br/>To define a module we need to create a Python class. PyTorch does not reinvent totally new ways of doing things as for example TensorFlow does. In PyTorch we tend to use pythonic ways to do things. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class EmbeddingDotProd(nn.Module):\n",
    "    def __init__(self, n_users, n_movies, n_factors):\n",
    "        super().__init__()\n",
    "        # Users embedding layer: dim = number of users x number of factors. \n",
    "        self.users = nn.Embedding(n_users, n_factors)\n",
    "        # Movies embedding layer: dim = number of movies x number of factors. \n",
    "        self.movies = nn.Embedding(n_movies, n_factors)\n",
    "        \n",
    "        # The two embedding matrices are randomly initialized (we do not use any pre-trained vectors)\n",
    "        # But it is important to randomly initialize them to a reasonable set of numbers / scale.\n",
    "        self.users.weight.data.uniform_(0, 0.05)\n",
    "        self.movies.weight.data.uniform_(0, 0.05)\n",
    "    \n",
    "    def forward(self, data):\n",
    "        u, m = data[:, 0], data[:, 1]\n",
    "        # Compute dot product between users vectors and movies vectors.\n",
    "        return (self.users(u) * self.movies(m)).sum(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fit(model, train_dl, n_epochs, optim, criterion):\n",
    "    bar = tqdm_notebook(total=n_epochs)\n",
    "    \n",
    "    avg_mom = 0.98\n",
    "    avg_loss = 0.\n",
    "    batch_num = 0\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        for i, batch in enumerate(train_dl):\n",
    "            batch_num += 1\n",
    "            \n",
    "            inp = Variable(batch[:, :2].long()).cuda()\n",
    "            targ = Variable(batch[:, 2].float()).cuda()\n",
    "        \n",
    "            # Forward pass: compute predicted y by passing x to the model.\n",
    "            pred = model(inp)\n",
    "\n",
    "            # Compute loss: we pass Variables containing the predicted and true values of y.\n",
    "            loss = criterion(pred, targ)\n",
    "\n",
    "            # Zero the gradients before running the backward pass.\n",
    "            opt.zero_grad()\n",
    "\n",
    "            # Backward pass: compute gradient of the loss with respect to all the learnable parameters of the model.\n",
    "            loss.backward()\n",
    "\n",
    "            # Calling the step function on an Optimizer makes an update to its parameters.\n",
    "            optim.step()\n",
    "            \n",
    "            # Exponentially weighted moving average, to make the reported loss more stable.\n",
    "            avg_loss = avg_loss * avg_mom + loss.data[0] * (1-avg_mom)\n",
    "            \n",
    "            # Compute bias-corrected loss estimate.\n",
    "            debias_loss = avg_loss / (1 - avg_mom**batch_num)\n",
    "        \n",
    "        # Compute validation loss.\n",
    "        val = validate(model, valid_dl, criterion)\n",
    "        \n",
    "        print(np.round([epoch, debias_loss] + val, 6))    \n",
    "        bar.update()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def validate(model, dl, criterion):\n",
    "    loss = []\n",
    "\n",
    "    for i, batch in enumerate(dl):\n",
    "        inp = Variable(batch[:, :2].long()).cuda()\n",
    "        targ = Variable(batch[:, 2].float()).cuda()\n",
    "        \n",
    "        # In order to compute validation loss we only do forward pass.\n",
    "        pred = model(inp)\n",
    "        \n",
    "        loss.append(criterion(pred, targ).data[0])\n",
    "    \n",
    "    return [np.mean(loss)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = EmbeddingDotProd(n_users, n_movies, 50).cuda()\n",
    "opt = optim.Adam(model.parameters(), 1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9db0320f0e8b47dd9854a67e00e51c27"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.       2.538217 2.357314]\n",
      "[1.       1.298426 1.410683]\n",
      "[2.       1.018669 1.208186]\n",
      "[3.       0.871076 1.145711]\n",
      "[4.       0.807154 1.116886]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fit(model, train_dl, 5, opt, nn.MSELoss())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loss used during training is Mean Squared Error. Let's calculate Root Mean Squared Error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.056828273656605"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "math.sqrt(1.116886)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Adding bias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For instance, a user could be pretty enthusiastic and have higher ratings on average, or some movie could be popular. We want to have a constant for users and a constant for movies that shape those features (in neural networks we call that a bias)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "min_rating = df['rating'].min()\n",
    "max_rating = df['rating'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_emb(num_embeddings, embedding_dim):\n",
    "    emb = nn.Embedding(num_embeddings, embedding_dim)\n",
    "    emb.weight.data.uniform_(-0.01, 0.01)\n",
    "    return emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class EmbeddingDotProdBias(nn.Module):\n",
    "    def __init__(self, n_users, n_movies, n_factors):\n",
    "        super().__init__()\n",
    "        self.users = get_emb(n_users, n_factors)\n",
    "        self.movies = get_emb(n_movies, n_factors)\n",
    "        # Bias embedding layer for users: dim = number of users x 1.\n",
    "        self.users_b = get_emb(n_users, 1)\n",
    "        # Bias embedding layer for movies: dim = number of movies x 1.\n",
    "        self.movies_b = get_emb(n_movies, 1)\n",
    "    \n",
    "    def forward(self, data):\n",
    "        u, m = data[:, 0], data[:, 1]\n",
    "        # Compute dot product between users vectors and movies vectors.\n",
    "        um = (self.users(u) * self.movies(m)).sum(1)\n",
    "        # Add bias\n",
    "        res = um + self.users_b(u).squeeze() + self.movies_b(m).squeeze()\n",
    "        # Transform results to desired output scale: min_rating - max_rating.\n",
    "        res = F.sigmoid(res) * (max_rating - min_rating) + min_rating\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# L2 regularization.\n",
    "weight_decay = 1e-4\n",
    "model = EmbeddingDotProdBias(n_users, n_movies, 50).cuda()\n",
    "opt = optim.Adam(model.parameters(), 1e-3, weight_decay=weight_decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5251de25d4654405bffa0567f5653463"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.       0.930192 0.896728]\n",
      "[1.       0.766666 0.816125]\n",
      "[2.       0.776622 0.7911  ]\n",
      "[3.       0.661314 0.778883]\n",
      "[4.       0.634662 0.772037]\n"
     ]
    }
   ],
   "source": [
    "fit(model, train_dl, 5, opt, nn.MSELoss())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8786563605870045"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "math.sqrt(0.772037)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This approach does not use a matrix factorization (i.e. creating a matrix with a row for each user and a column for each movie). In that case, any empty user-movie combination is filled with zero. As a result we get a sparse matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/>The probabilistic matrix factorization approach that is used here takes advantage of the fact that our data structure actually looks like a typical table rather than a cross tab, therefore is only calculated the loss for user - movie combinations that actually appears."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We save learned weights for future visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Module.parameters of EmbeddingDotProdBias(\n",
       "  (users): Embedding(671, 50)\n",
       "  (movies): Embedding(9066, 50)\n",
       "  (users_b): Embedding(671, 1)\n",
       "  (movies_b): Embedding(9066, 1)\n",
       ")>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pickle.dump(model.users, open(f'data/users_emb.pickle', 'wb')) \n",
    "pickle.dump(model.movies, open(f'data/movies_emb.pickle', 'wb'))\n",
    "pickle.dump(model.users_b, open(f'data/users_bias.pickle', 'wb')) \n",
    "pickle.dump(model.movies_b, open(f'data/movies_bias.pickle', 'wb')) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
